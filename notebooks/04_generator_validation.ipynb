{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc19a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9413e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem, rdBase\n",
    "from rdkit.Chem import Descriptors\n",
    "from src import sascorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c49c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdBase.DisableLog('rdApp.error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8270bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, vocab_size, prop_dim, d_model=256, nhead=8, num_layers=4, max_len=128, dropout=0.1): \n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "        self.prop_embed = nn.Linear(prop_dim, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=512,\n",
    "            batch_first=False,\n",
    "            dropout=dropout  \n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, props):\n",
    "        src = torch.clamp(src, 0, self.token_embed.num_embeddings - 1)\n",
    "        B, L = src.shape\n",
    "        tok_emb = self.token_embed(src) * (self.d_model ** 0.5)\n",
    "        pos = torch.arange(L, device=src.device).unsqueeze(0)\n",
    "        pos_emb = self.pos_embed(pos)\n",
    "        prop_emb = self.prop_embed(props).unsqueeze(1)\n",
    "        \n",
    "        x = tok_emb + pos_emb + prop_emb\n",
    "        x = self.dropout(x) \n",
    "        x = x.transpose(0, 1)  \n",
    "        \n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(L).to(src.device)\n",
    "        out = self.transformer(x, mask=tgt_mask)\n",
    "        \n",
    "        out = out.transpose(0, 1) \n",
    "        logits = self.fc_out(out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d399f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_maps():\n",
    "    \"\"\"Returns the token-to-ID and ID-to-token maps.\"\"\"\n",
    "    token_to_idx = {\n",
    "    \"#\": 2, \"%\": 3, \"(\": 4, \")\": 5, \"+\": 6, \"-\": 7, \".\": 8, \"/\": 9, \"0\": 10, \"1\": 11, \"2\": 12, \"3\": 13,\n",
    "    \"4\": 14, \"5\": 15, \"6\": 16, \"7\": 17, \"8\": 18, \"9\": 19, \"=\": 20, \"@\": 21, \"A\": 22, \"B\": 23, \"C\": 24,\n",
    "    \"D\": 25, \"E\": 26, \"F\": 27, \"G\": 28, \"H\": 29, \"I\": 30, \"K\": 31, \"L\": 32, \"M\": 33, \"N\": 34, \"O\": 35,\n",
    "    \"P\": 36, \"R\": 37, \"S\": 38, \"T\": 39, \"U\": 40, \"V\": 41, \"W\": 42, \"X\": 43, \"Y\": 44, \"Z\": 45, \"[\": 46,\n",
    "    \"\\\\\": 47, \"]\": 48, \"a\": 49, \"b\": 50, \"c\": 51, \"d\": 52, \"e\": 53, \"f\": 54, \"g\": 55, \"h\": 56, \"i\": 57,\n",
    "    \"k\": 58, \"l\": 59, \"m\": 60, \"n\": 61, \"o\": 62, \"p\": 63, \"r\": 64, \"s\": 65, \"t\": 66, \"u\": 67,\n",
    "    \"y\": 68, \"<PAD>\": 0, \"<START>\": 1, \"<END>\": 69}\n",
    "    idx_to_token = {v: k for k, v in token_to_idx.items()}\n",
    "    return token_to_idx, idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9fd645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path, device):\n",
    "    \"\"\"Loads the generator model from a checkpoint.\"\"\"\n",
    "    # Model parameters\n",
    "    vocab_size = 70\n",
    "    prop_dim = 5\n",
    "    max_len_model = 128\n",
    "    \n",
    "    model = Generator(vocab_size, prop_dim, max_len=max_len_model, dropout=0.1).to(device)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"âœ… Loaded model from epoch {checkpoint['epoch']} with loss {checkpoint['loss']:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_smiles(training_data_path):\n",
    "    \"\"\"Loads the canonical SMILES from the training set for novelty check.\"\"\"\n",
    "    print(f\"Loading training data from {training_data_path} for novelty check...\")\n",
    "    df = pd.read_csv(training_data_path)\n",
    "    training_smiles = set(df['canonical'].tolist())\n",
    "    print(f\"Found {len(training_smiles)} unique training SMILES.\")\n",
    "    return training_smiles\n",
    "\n",
    "def decode_smiles(tensor, idx_to_token):\n",
    "    \"\"\"Decodes a tensor of IDs into a SMILES string.\"\"\"\n",
    "    smiles_list = []\n",
    "    for row in tensor:\n",
    "        smi = \"\"\n",
    "        for idx in row:\n",
    "            idx = idx.item()\n",
    "            if idx == 1: \n",
    "                continue\n",
    "            if idx == 69: \n",
    "                break\n",
    "            if idx == 0: \n",
    "                break\n",
    "            smi += idx_to_token.get(idx, '?')\n",
    "        smiles_list.append(smi)\n",
    "    return smiles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65361ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_validate(model, props_to_use, token_maps, device, num_to_gen, gen_batch_size, training_smiles):\n",
    "    \n",
    "    _, idx_to_token = token_maps\n",
    "    start_token_id = 1\n",
    "    stop_token_id = 69\n",
    "    max_gen_len = 128\n",
    "    top_k = 50\n",
    "\n",
    "    all_generated_smiles = []\n",
    "    all_valid_smiles = []\n",
    "    \n",
    "    # Store calculated properties\n",
    "    props_calculated = {\n",
    "        'QED': [], 'LogP': [], 'MolWt': [], 'TPSA': [] , 'SAS': []\n",
    "    }\n",
    "    \n",
    "    # Calculate how many batches we need\n",
    "    num_batches = int(np.ceil(num_to_gen / gen_batch_size))\n",
    "\n",
    "    for _ in tqdm(range(num_batches), desc=\"Generating molecules\"):\n",
    "        # Generate a batch\n",
    "        generated = torch.tensor([[start_token_id]] * gen_batch_size, dtype=torch.long).to(device)\n",
    "        \n",
    "        props_batch = props_to_use.repeat(gen_batch_size, 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_gen_len):\n",
    "                logits = model(generated, props_batch)\n",
    "                last_logits = logits[:, -1, :] \n",
    "                \n",
    "                v, _ = torch.topk(last_logits, top_k)\n",
    "                last_logits[last_logits < v[:, [-1]]] = -float('Inf')\n",
    "                \n",
    "                probs = F.softmax(last_logits, dim=-1)\n",
    "                next_token = torch.multinomial(probs, num_samples=1)\n",
    "                generated = torch.cat([generated, next_token], dim=1)\n",
    "                \n",
    "                if (next_token == stop_token_id).all():\n",
    "                    break\n",
    "        \n",
    "        # Decode and Validate the batch\n",
    "        decoded_batch = decode_smiles(generated, idx_to_token)\n",
    "        all_generated_smiles.extend(decoded_batch)\n",
    "\n",
    "        for smi in decoded_batch:\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            if mol: # If molecule is valid\n",
    "                all_valid_smiles.append(smi)\n",
    "                props_calculated['QED'].append(Descriptors.qed(mol))\n",
    "                props_calculated['LogP'].append(Descriptors.MolLogP(mol))\n",
    "                props_calculated['MolWt'].append(Descriptors.MolWt(mol))\n",
    "                props_calculated['TPSA'].append(Descriptors.TPSA(mol))\n",
    "                props_calculated['SAS'].append(sascorer.calculateScore(mol))\n",
    "\n",
    "    # Calculate Metrics\n",
    "    num_generated = len(all_generated_smiles)\n",
    "    num_valid = len(all_valid_smiles)\n",
    "    \n",
    "    if num_valid == 0:\n",
    "        print(\" No valid molecules were generated.\")\n",
    "        return\n",
    "\n",
    "    validity = num_valid / num_generated\n",
    "    \n",
    "    # Uniqueness\n",
    "    valid_set = set(all_valid_smiles)\n",
    "    uniqueness = len(valid_set) / num_valid\n",
    "\n",
    "    # Novelty\n",
    "    novel_smiles = [s for s in valid_set if s not in training_smiles]\n",
    "    novelty = len(novel_smiles) / len(valid_set)\n",
    "\n",
    "    # Print Report\n",
    "    print(\"\\n--- METRICS ---\")\n",
    "    print(f\"Total Generated: {num_generated}\")\n",
    "    print(f\" Validity:     {validity * 100:.2f}% ({num_valid} molecules)\")\n",
    "    print(f\" Uniqueness:   {uniqueness * 100:.2f}% ({len(valid_set)} unique)\")\n",
    "    print(f\" Novelty:      {novelty * 100:.2f}% ({len(novel_smiles)} novel)\")\n",
    "\n",
    "    # Print Property Report\n",
    "    print(\"\\n--- PROPERTY ANALYSIS (of valid molecules) ---\")\n",
    "    print(f\"Target Props (Normalized): {props_to_use[0].cpu().numpy()}\")\n",
    "    print(\"Actual Props (Un-normalized, Avg):\")\n",
    "    for key, values in props_calculated.items():\n",
    "        if values:\n",
    "            print(f\"  {key}: {np.mean(values):.4f}\")\n",
    "            \n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3072ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "âœ… Loaded model from epoch 50 with loss 0.6450\n",
      "Loading training data from ../data/processed_5l/train_properties.csv for novelty check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhanu\\Desktop\\bio-info data\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 278937 unique training SMILES.\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = \"../results/models_5l/u&c_generator_epoch_50.pt\" \n",
    "TRAINING_DATA_PATH = \"../data/processed_5l/train_properties.csv\" \n",
    "\n",
    "NUM_TO_GENERATE = 1000\n",
    "GEN_BATCH_SIZE = 32 \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = load_model(CHECKPOINT_PATH, device)\n",
    "token_maps = get_token_maps()\n",
    "training_smiles = load_training_smiles(TRAINING_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94b095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. VALIDATING: Conditional Generation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating molecules: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:24<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- METRICS ---\n",
      "Total Generated: 1024\n",
      "âœ… Validity:     75.78% (776 molecules)\n",
      "âœ¨ Uniqueness:   100.00% (776 unique)\n",
      "ðŸ’¡ Novelty:      99.74% (774 novel)\n",
      "\n",
      "--- PROPERTY ANALYSIS (of valid molecules) ---\n",
      "Target Props (Normalized): [0.8781115  0.07833407 0.6368721  0.03738495 0.09905331]\n",
      "Actual Props (Un-normalized, Avg):\n",
      "  QED: 0.3667\n",
      "  LogP: 3.3454\n",
      "  MolWt: 463.5802\n",
      "  TPSA: 140.1037\n",
      "  SAS: 2.3691\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Conditional Generation\n",
    "target_props = torch.tensor([[\n",
    "    0.8781114617473635,0.07833406806496232,0.6368721378699783,0.03738495242074764,0.09905331048030695 # a sample from testing dataset\n",
    "]], dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"--- 1. VALIDATING: Conditional Generation ---\")\n",
    "generate_and_validate(\n",
    "    model, \n",
    "    props_to_use=target_props,\n",
    "    token_maps=token_maps,\n",
    "    device=device,\n",
    "    num_to_gen=NUM_TO_GENERATE,\n",
    "    gen_batch_size=GEN_BATCH_SIZE,\n",
    "    training_smiles=training_smiles\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a874782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. VALIDATING: Unconditional Generation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating molecules: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:24<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- METRICS ---\n",
      "Total Generated: 1024\n",
      "âœ… Validity:     81.35% (833 molecules)\n",
      "âœ¨ Uniqueness:   99.76% (831 unique)\n",
      "ðŸ’¡ Novelty:      92.06% (765 novel)\n",
      "\n",
      "--- PROPERTY ANALYSIS (of valid molecules) ---\n",
      "Target Props (Normalized): [0. 0. 0. 0. 0.]\n",
      "Actual Props (Un-normalized, Avg):\n",
      "  QED: 0.5285\n",
      "  LogP: 2.5194\n",
      "  MolWt: 298.0055\n",
      "  TPSA: 65.2163\n",
      "  SAS: 2.9442\n",
      "\n",
      "========================================\n",
      "\n",
      "âœ… Validation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Unconditional Generation\n",
    "uncond_props = torch.zeros((1, 5), dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"VALIDATING: Unconditional Generation ---\")\n",
    "generate_and_validate(\n",
    "    model, \n",
    "    props_to_use=uncond_props,\n",
    "    token_maps=token_maps,\n",
    "    device=device,\n",
    "    num_to_gen=NUM_TO_GENERATE,\n",
    "    gen_batch_size=GEN_BATCH_SIZE,\n",
    "    training_smiles=training_smiles\n",
    ")\n",
    "\n",
    "print(\"Validation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
