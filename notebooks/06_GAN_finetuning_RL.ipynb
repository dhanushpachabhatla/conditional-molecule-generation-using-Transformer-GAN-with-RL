{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3648a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os, gc\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "from rdkit import Chem, rdBase\n",
    "from rdkit.Chem import Descriptors\n",
    "from src import sascorer\n",
    "\n",
    "rdBase.DisableLog('rdApp.error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b592bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, vocab_size, prop_dim, d_model=256, nhead=8, num_layers=4, max_len=128, dropout=0.1): \n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "        self.prop_embed = nn.Linear(prop_dim, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=512, batch_first=False, dropout=dropout  \n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, props):\n",
    "        src = torch.clamp(src, 0, self.token_embed.num_embeddings - 1)\n",
    "        B, L = src.shape\n",
    "        tok_emb = self.token_embed(src) * (self.d_model ** 0.5)\n",
    "        pos = torch.arange(L, device=src.device).unsqueeze(0)\n",
    "        pos_emb = self.pos_embed(pos)\n",
    "        prop_emb = self.prop_embed(props).unsqueeze(1)\n",
    "        \n",
    "        x = tok_emb + pos_emb + prop_emb\n",
    "        x = self.dropout(x) \n",
    "        x = x.transpose(0, 1)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(L).to(src.device)\n",
    "        out = self.transformer(x, mask=tgt_mask)\n",
    "        out = out.transpose(0, 1) \n",
    "        logits = self.fc_out(out)\n",
    "        return logits\n",
    "\n",
    "    def sample(self, props_to_use, token_maps, max_len=128, top_k=50):\n",
    "        token_to_idx, _ = token_maps\n",
    "        start_token_id = token_to_idx['<START>']\n",
    "        stop_token_id  = token_to_idx['<END>']\n",
    "        pad_token_id   = token_to_idx['<PAD>']\n",
    "    \n",
    "        batch_size = props_to_use.size(0)\n",
    "        device = props_to_use.device\n",
    "    \n",
    "        generated_seqs = torch.full((batch_size, 1), start_token_id, dtype=torch.long, device=device)\n",
    "        sum_log_probs = torch.zeros(batch_size, device=device)\n",
    "    \n",
    "        for t in range(max_len - 1):\n",
    "    \n",
    "            # Forward with grads ON → log_probs have grad_fn\n",
    "            logits = self.forward(generated_seqs, props_to_use)\n",
    "            last_logits = logits[:, -1, :]\n",
    "    \n",
    "            # Top-k filtering\n",
    "            v, _ = torch.topk(last_logits, top_k, dim=-1)\n",
    "            last_logits[last_logits < v[:, [-1]]] = -float(\"inf\")\n",
    "    \n",
    "            probs = F.softmax(last_logits, dim=-1)\n",
    "            log_probs = F.log_softmax(last_logits, dim=-1)\n",
    "    \n",
    "            # Non-differentiable sampling\n",
    "            with torch.no_grad():\n",
    "                next_token = torch.multinomial(probs, num_samples=1)\n",
    "    \n",
    "            # Log-prob of chosen token (differentiable)\n",
    "            chosen_logprob = log_probs.gather(1, next_token).squeeze(1)\n",
    "    \n",
    "            not_finished = (generated_seqs[:, -1] != stop_token_id).float()\n",
    "            sum_log_probs += chosen_logprob * not_finished\n",
    "    \n",
    "            generated_seqs = torch.cat([generated_seqs, next_token], dim=1)\n",
    "    \n",
    "            # detach so graph doesn't grow across timesteps\n",
    "            generated_seqs = generated_seqs.detach()\n",
    "    \n",
    "            if not_finished.sum() == 0:\n",
    "                break\n",
    "    \n",
    "        # Pad to max_len (no grad)\n",
    "        with torch.no_grad():\n",
    "            B, L = generated_seqs.shape\n",
    "            if L < max_len:\n",
    "                pads = torch.full((B, max_len - L), pad_token_id, dtype=torch.long, device=device)\n",
    "                generated_seqs = torch.cat([generated_seqs, pads], dim=1)\n",
    "    \n",
    "        return generated_seqs, sum_log_probs\n",
    "\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, vocab_size, prop_dim, d_model=256, nhead=8, num_layers=4, max_len=128, dropout=0.1): \n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "        self.prop_embed = nn.Linear(prop_dim, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=512, batch_first=False, dropout=dropout  \n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc_out = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, src, props):\n",
    "        src = torch.clamp(src, 0, self.token_embed.num_embeddings - 1)\n",
    "        B, L = src.shape\n",
    "        tok_emb = self.token_embed(src) * (self.d_model ** 0.5)\n",
    "        pos = torch.arange(L, device=src.device).unsqueeze(0)\n",
    "        pos_emb = self.pos_embed(pos)\n",
    "        prop_emb = self.prop_embed(props).unsqueeze(1)\n",
    "        \n",
    "        x = tok_emb + pos_emb + prop_emb\n",
    "        x = self.dropout(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        out = self.transformer(x)\n",
    "        pooled_output = out[0, :, :]\n",
    "        logit = self.fc_out(pooled_output) \n",
    "        return logit.squeeze(-1)\n",
    "\n",
    "\n",
    "class PropertyDataset(Dataset):\n",
    "    def __init__(self, properties_csv):\n",
    "        super().__init__()\n",
    "        self.props_df = pd.read_csv(properties_csv)\n",
    "        self.prop_columns = ['QED', 'SAS', 'LogP', 'TPSA', 'MolWt']\n",
    "        self.properties = torch.tensor(\n",
    "            self.props_df[self.prop_columns].values,\n",
    "            dtype=torch.float\n",
    "        )\n",
    "        print(f\" Loaded {len(self.properties)} target properties.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.properties)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.properties[idx]\n",
    "\n",
    "\n",
    "def get_token_maps():\n",
    "    token_to_idx = {\n",
    "    \"#\": 2, \"%\": 3, \"(\": 4, \")\": 5, \"+\": 6, \"-\": 7, \".\": 8, \"/\": 9, \"0\": 10, \"1\": 11, \"2\": 12, \"3\": 13,\n",
    "    \"4\": 14, \"5\": 15, \"6\": 16, \"7\": 17, \"8\": 18, \"9\": 19, \"=\": 20, \"@\": 21, \"A\": 22, \"B\": 23, \"C\": 24,\n",
    "    \"D\": 25, \"E\": 26, \"F\": 27, \"G\": 28, \"H\": 29, \"I\": 30, \"K\": 31, \"L\": 32, \"M\": 33, \"N\": 34, \"O\": 35,\n",
    "    \"P\": 36, \"R\": 37, \"S\": 38, \"T\": 39, \"U\": 40, \"V\": 41, \"W\": 42, \"X\": 43, \"Y\": 44, \"Z\": 45, \"[\": 46,\n",
    "    \"\\\\\": 47, \"]\": 48, \"a\": 49, \"b\": 50, \"c\": 51, \"d\": 52, \"e\": 53, \"f\": 54, \"g\": 55, \"h\": 56, \"i\": 57,\n",
    "    \"k\": 58, \"l\": 59, \"m\": 60, \"n\": 61, \"o\": 62, \"p\": 63, \"r\": 64, \"s\": 65, \"t\": 66, \"u\": 67,\n",
    "    \"y\": 68, \"<PAD>\": 0, \"<START>\": 1, \"<END>\": 69}\n",
    "    idx_to_token = {v: k for k, v in token_to_idx.items()}\n",
    "    return token_to_idx, idx_to_token\n",
    "\n",
    "\n",
    "def decode_smiles(tensor, idx_to_token):\n",
    "    smiles_list = []\n",
    "    for row in tensor:\n",
    "        smi = \"\"\n",
    "        for idx in row:\n",
    "            idx = idx.item()\n",
    "            if idx == 1: continue\n",
    "            if idx == 69: break\n",
    "            if idx == 0:  break\n",
    "            smi += idx_to_token.get(idx, '?')\n",
    "        smiles_list.append(smi)\n",
    "    return smiles_list\n",
    "\n",
    "\n",
    "def calculate_properties(smiles_list, device):\n",
    "    props = []\n",
    "    for smi in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol:\n",
    "            try:\n",
    "                qed = Descriptors.qed(mol)\n",
    "                sas = sascorer.calculateScore(mol)\n",
    "                logp = Descriptors.MolLogP(mol)\n",
    "                tpsa = Descriptors.TPSA(mol)\n",
    "                mw = Descriptors.MolWt(mol)\n",
    "                props.append([qed, sas, logp, tpsa, mw])\n",
    "            except:\n",
    "                props.append([0.0] * 5)\n",
    "        else:\n",
    "            props.append([0.0] * 5)\n",
    "    return torch.tensor(props, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      " Loaded 278937 target properties.\n",
      "Loading property stats from ../data/processed_5l/property_stats.json...\n",
      "Loaded property stats (Min): [ 3.9431723e-03  1.0000000e+00 -8.7627800e+01  0.0000000e+00\n",
      "  1.0080000e+00]\n",
      "Loaded property stats (Max):  [9.4825125e-01 1.0000000e+01 5.9808720e+01 4.2015000e+03 1.8838697e+04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhanu\\Desktop\\bio-info data\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded Generator from epoch 50\n",
      " Loaded Discriminator and set to eval() mode (weights frozen).\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_DIR = \"../results/models_5l/\"\n",
    "TRAIN_PROPERTIES_CSV = \"../data/processed_5l/train_properties.csv\"\n",
    "GEN_CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"u&c_generator_epoch_50.pt\") \n",
    "DISC_CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"discriminator_epoch_1.pt\")\n",
    "\n",
    "STATS_PATH = \"../data/processed_5l/property_stats.json\" \n",
    "\n",
    "VOCAB_SIZE = 70 \n",
    "PROP_DIM = 5\n",
    "D_MODEL = 256\n",
    "N_HEAD = 8\n",
    "NUM_LAYERS = 4\n",
    "MAX_LEN = 128\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# RL Training Hyperparameters\n",
    "RL_STEPS = 5000\n",
    "BATCH_SIZE = 8 \n",
    "G_LEARNING_RATE = 1e-5\n",
    "p_uncond = 0.1\n",
    "W_DISC = 0.2\n",
    "W_PROP = 0.8\n",
    "\n",
    "# 1. Setup Device and Token Maps\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "token_to_idx, idx_to_token = get_token_maps()\n",
    "token_maps = (token_to_idx, idx_to_token)\n",
    "\n",
    "# 2. Load Property Data\n",
    "prop_dataset = PropertyDataset(properties_csv=TRAIN_PROPERTIES_CSV)\n",
    "prop_dataloader = DataLoader(prop_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "prop_iter = iter(prop_dataloader)\n",
    "\n",
    "\n",
    "print(f\"Loading property stats from {STATS_PATH}...\")\n",
    "try:\n",
    "    with open(STATS_PATH, 'r') as f:\n",
    "        loaded_stats = json.load(f)\n",
    "    \n",
    "    prop_cols = ['QED', 'SAS', 'LogP', 'TPSA', 'MolWt']\n",
    "    prop_stats = {\n",
    "        'min': torch.tensor([loaded_stats['min'][col] for col in prop_cols], dtype=torch.float32).to(device),\n",
    "        'max': torch.tensor([loaded_stats['max'][col] for col in prop_cols], dtype=torch.float32).to(device)\n",
    "    }\n",
    "    prop_stats['range'] = (prop_stats['max'] - prop_stats['min']) + 1e-8 \n",
    "\n",
    "    print(f\"Loaded property stats (Min): {prop_stats['min'].cpu().numpy()}\")\n",
    "    print(f\"Loaded property stats (Max):  {prop_stats['max'].cpu().numpy()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\" FATAL ERROR: prop_stats.json not found at {STATS_PATH}\")\n",
    "    print(\"Please re-run your preprocessing script to create this file.\")\n",
    "    # This will stop the notebook from proceeding\n",
    "    raise\n",
    "\n",
    "# 4. Load Pre-trained Generator\n",
    "generator = Generator(\n",
    "    vocab_size=VOCAB_SIZE, prop_dim=PROP_DIM, d_model=D_MODEL, nhead=N_HEAD, \n",
    "    num_layers=NUM_LAYERS, max_len=MAX_LEN, dropout=DROPOUT\n",
    ").to(device)\n",
    "gen_checkpoint = torch.load(GEN_CHECKPOINT_PATH, map_location=device, weights_only=True)\n",
    "generator.load_state_dict(gen_checkpoint['model_state_dict'])\n",
    "print(f\" Loaded Generator from epoch {gen_checkpoint['epoch']}\")\n",
    "\n",
    "# 5. Load Pre-trained Discriminator\n",
    "discriminator = Discriminator(\n",
    "    vocab_size=VOCAB_SIZE, prop_dim=PROP_DIM, d_model=D_MODEL, nhead=N_HEAD, \n",
    "    num_layers=NUM_LAYERS, max_len=MAX_LEN, dropout=DROPOUT\n",
    ").to(device)\n",
    "disc_checkpoint = torch.load(DISC_CHECKPOINT_PATH, map_location=device, weights_only=True)\n",
    "\n",
    "# 6. FREEZE Discriminator\n",
    "discriminator.load_state_dict(disc_checkpoint['model_state_dict'])\n",
    "discriminator.eval()\n",
    "for param in discriminator.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\" Loaded Discriminator and set to eval() mode (weights frozen).\")\n",
    "    \n",
    "# 7. Setup Generator Optimizer\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=G_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca064b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BATCH_SIZE = 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Step:  10%|█         | 501/5000 [24:02<3:53:07,  3.11s/it, loss=-4.5367, mse=0.007, rD=0.000, rP=0.889, tot=0.862, val=0.75] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checkpoint saved to ../results/models_5l//generator_RL_step_500.pt ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Step:  20%|██        | 1001/5000 [48:19<2:27:25,  2.21s/it, loss=-1.0539, mse=0.002, rD=1.000, rP=0.966, tot=1.173, val=1.00] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checkpoint saved to ../results/models_5l//generator_RL_step_1000.pt ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Step:  30%|███       | 1501/5000 [1:07:30<2:02:51,  2.11s/it, loss=-0.6417, mse=0.043, rD=0.000, rP=0.454, tot=0.563, val=1.00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checkpoint saved to ../results/models_5l//generator_RL_step_1500.pt ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Step:  40%|████      | 2001/5000 [1:21:44<1:14:18,  1.49s/it, loss=-5.9659, mse=0.015, rD=1.000, rP=0.872, tot=1.073, val=0.88] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checkpoint saved to ../results/models_5l//generator_RL_step_2000.pt ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Step:  50%|█████     | 2501/5000 [1:40:35<2:00:42,  2.90s/it, loss=-1.8318, mse=0.002, rD=0.000, rP=0.970, tot=0.976, val=1.00] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checkpoint saved to ../results/models_5l//generator_RL_step_2500.pt ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Step:  60%|██████    | 3001/5000 [2:00:15<29:07,  1.14it/s, loss=-1.6198, mse=0.001, rD=1.000, rP=0.979, tot=1.183, val=1.00]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checkpoint saved to ../results/models_5l//generator_RL_step_3000.pt ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Step:  68%|██████▊   | 3422/5000 [2:17:22<1:17:13,  2.94s/it, loss=-2.3486, mse=0.001, rD=0.000, rP=0.980, tot=0.984, val=1.00] [01:37:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:37:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:37:08] WARNING: not removing hydrogen atom without neighbors\n",
      "RL Step:  70%|███████   | 3501/5000 [2:21:14<1:12:13,  2.89s/it, loss=-2.8551, mse=0.001, rD=0.000, rP=0.979, tot=0.983, val=1.00] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checkpoint saved to ../results/models_5l//generator_RL_step_3500.pt ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Step:  80%|████████  | 4001/5000 [2:46:04<47:44,  2.87s/it, loss=-5.3314, mse=0.002, rD=0.000, rP=0.964, tot=0.971, val=1.00]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checkpoint saved to ../results/models_5l//generator_RL_step_4000.pt ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Step:  90%|█████████ | 4501/5000 [3:10:28<24:34,  2.96s/it, loss=8.1686, mse=0.001, rD=0.000, rP=0.988, tot=0.990, val=1.00] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checkpoint saved to ../results/models_5l//generator_RL_step_4500.pt ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Step: 100%|██████████| 5000/5000 [3:35:10<00:00,  2.58s/it, loss=-4.3154, mse=0.006, rD=0.001, rP=0.896, tot=0.892, val=0.88]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RL Fine-Tuning Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RL FINE-TUNING LOOP\n",
    "print(f\"Using BATCH_SIZE = {BATCH_SIZE}.\")\n",
    "baseline = None  # EMA baseline\n",
    "\n",
    "tqdm_iter = tqdm(range(RL_STEPS), desc=\"RL Step\")\n",
    "\n",
    "for step in tqdm_iter:\n",
    "    generator.train()\n",
    "\n",
    "    # 1. Target Properties\n",
    "    try:\n",
    "        target_props_raw = next(prop_iter)\n",
    "    except StopIteration:\n",
    "        prop_iter = iter(prop_dataloader)\n",
    "        target_props_raw = next(prop_iter)\n",
    "\n",
    "    if target_props_raw.shape[0] != BATCH_SIZE:\n",
    "        prop_iter = iter(prop_dataloader)\n",
    "        target_props_raw = next(prop_iter)\n",
    "\n",
    "    target_props_raw = target_props_raw.to(device)\n",
    "\n",
    "    # Normalize target props to [0,1]\n",
    "    target_props = (target_props_raw - prop_stats['min']) / prop_stats['range']\n",
    "    target_props = torch.clamp(target_props, 0.0, 1.0)\n",
    "\n",
    "    # 2. Conditional dropping\n",
    "    props_to_use = target_props\n",
    "    if torch.rand(1).item() < p_uncond:\n",
    "        props_to_use = torch.zeros_like(target_props)\n",
    "\n",
    "    # 3. Generate fake molecules\n",
    "    fake_seqs, sum_log_probs = generator.sample(props_to_use, token_maps, max_len=MAX_LEN)\n",
    "\n",
    "    # 4. Rewards\n",
    "    # Discriminator reward\n",
    "    disc_logits = discriminator(fake_seqs.detach(), props_to_use)\n",
    "    reward_D = torch.sigmoid(disc_logits)     # [B] in (0,1)\n",
    "\n",
    "    # Decode SMILES\n",
    "    smiles_list = decode_smiles(fake_seqs.detach(), idx_to_token)\n",
    "\n",
    "    # RDKit props\n",
    "    actual_props = calculate_properties(smiles_list, device)\n",
    "    actual_props_norm = (actual_props - prop_stats['min']) / prop_stats['range']\n",
    "    actual_props_norm = torch.clamp(actual_props_norm, 0.0, 1.0)\n",
    "\n",
    "    # MSE per sample\n",
    "    mse_per_item = F.mse_loss(actual_props_norm, target_props, reduction=\"none\").mean(dim=1)\n",
    "\n",
    "    # Proposed Property Reward\n",
    "    # r = exp(-beta * mse), β=20\n",
    "    beta = 20.0\n",
    "    reward_P = torch.exp(-beta * mse_per_item)    # (0,1]\n",
    "\n",
    "    # Validity reward\n",
    "    valid_list = [1.0 if Chem.MolFromSmiles(s) else 0.0 for s in smiles_list]\n",
    "    reward_valid = torch.tensor(valid_list, device=device, dtype=torch.float32)\n",
    "\n",
    "    # TOTAL reward\n",
    "    total_reward = (\n",
    "        W_DISC * reward_D +\n",
    "        W_PROP * reward_P +\n",
    "        0.2 * reward_valid      # validity reward weight\n",
    "    )\n",
    "\n",
    "    # Advantage (baseline + normalization)\n",
    "    if baseline is None:\n",
    "        baseline = total_reward.mean().detach()\n",
    "    else:\n",
    "        baseline = 0.99 * baseline + 0.01 * total_reward.mean().detach()\n",
    "\n",
    "    advantage = total_reward - baseline\n",
    "    advantage = (advantage - advantage.mean()) / (advantage.std() + 1e-8)\n",
    "\n",
    "    # POLICY GRADIENT LOSS\n",
    "    policy_loss = - (sum_log_probs * advantage.detach()).mean()\n",
    "\n",
    "    optimizer_G.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    # LOGGING\n",
    "    if step % 50 == 0:\n",
    "        frac_valid = float(sum(valid_list)) / len(valid_list)\n",
    "        avg_mse = mse_per_item.mean().item()\n",
    "\n",
    "        tqdm_iter.set_postfix(\n",
    "            loss=f\"{policy_loss.item():.4f}\",\n",
    "            val=f\"{frac_valid:.2f}\",\n",
    "            mse=f\"{avg_mse:.3f}\",\n",
    "            rD=f\"{reward_D.mean().item():.3f}\",\n",
    "            rP=f\"{reward_P.mean().item():.3f}\",\n",
    "            tot=f\"{total_reward.mean().item():.3f}\"\n",
    "        )\n",
    "\n",
    "    # Checkpoint\n",
    "    if step > 0 and step % 500 == 0:\n",
    "        path = f\"{CHECKPOINT_DIR}/generator_RL_step_{step}.pt\"\n",
    "        torch.save({\n",
    "            \"step\": step,\n",
    "            \"model_state_dict\": generator.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer_G.state_dict(),\n",
    "        }, path)\n",
    "        print(f\"\\n--- Checkpoint saved to {path} ---\")\n",
    "\n",
    "print(\"RL Fine-Tuning Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "449ab0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e40959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checkpoint saved to ../results/models_5l//generator_RL_step_5000.pt ---\n"
     ]
    }
   ],
   "source": [
    "path = f\"{CHECKPOINT_DIR}/generator_RL_step_{step+1}.pt\"\n",
    "torch.save({\n",
    "    \"step\": step+1,\n",
    "    \"model_state_dict\": generator.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer_G.state_dict(),\n",
    "    }, path)\n",
    "print(f\"\\n--- Checkpoint saved to {path} ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
